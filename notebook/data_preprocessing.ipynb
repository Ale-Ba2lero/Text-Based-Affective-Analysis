{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\aless\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:393: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "D:\\Users\\aless\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import read_matlab_files as rmf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate CSV from ZuCo 2.0 Matlab files\n",
    "\n",
    "Get all the words used in the dataset (no repetition) remove punctuation and make everything lowercase.\n",
    "\n",
    "Clculate mean value and standard deviation fo the pupil size for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Word          GD         TRT         FFD         GPT      nFix  \\\n",
      "0                he  111.567944  131.538328  108.419861  155.580139  1.195122   \n",
      "1               was  110.516347  141.401917  104.174746  137.103720  1.293123   \n",
      "2              also  108.709402  152.076923   99.393162  139.735043  1.495726   \n",
      "3               the  108.107385  130.697804  105.385629  159.079042  1.229940   \n",
      "4      unsuccessful  133.500000  268.111111  105.000000  242.611111  2.444444   \n",
      "...             ...         ...         ...         ...         ...       ...   \n",
      "2176         oakley   95.764706  140.352941   91.470588  125.647059  1.411765   \n",
      "2177        network  120.125000  204.750000  120.125000  445.625000  1.375000   \n",
      "2178       banister  148.642857  222.357143  106.928571  173.928571  2.142857   \n",
      "2179         bureau  102.153846  102.153846   95.846154  124.000000  1.076923   \n",
      "2180  investigation  139.916667  181.333333  122.583333  450.166667  1.500000   \n",
      "\n",
      "              MPS  \n",
      "0     3361.716899  \n",
      "1     3330.888001  \n",
      "2     3243.967949  \n",
      "3     3315.473426  \n",
      "4     3442.759259  \n",
      "...           ...  \n",
      "2176  3059.254902  \n",
      "2177  3202.687500  \n",
      "2178  3303.098810  \n",
      "2179  3208.769231  \n",
      "2180  3185.541667  \n",
      "\n",
      "[2181 rows x 7 columns]\n",
      "Wall time: 9min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "zuco_ds = rmf.getWordsMeanValues()\n",
    "zuco_ds.to_csv('Lexicons/ZuCo_words_dataset.csv', index=False)\n",
    "\n",
    "print(zuco_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and convert NRC-Emotion-Intensity-Lexicon-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-Lexicon-v1.txt', 'r') as in_file:\n",
    "    stripped = (line.strip() for line in in_file)\n",
    "    lines = (line.split('\\t') for line in stripped if line)\n",
    "    with open (r'Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-Lexicon-v1.csv', 'w', newline='') as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        writer.writerow(('Word', 'Emotion', 'EmotionIntensityScore'))\n",
    "        writer.writerows(lines)\n",
    "        \n",
    "emotion_intensity_dataset = pd.read_csv(r'Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-Lexicon-v1.csv')\n",
    "print(emotion_intensity_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anger score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-anger-scores.txt', 'r') as in_file:\n",
    "    stripped = (line.strip() for line in in_file)\n",
    "    lines = (line.split('\\t') for line in stripped if line)\n",
    "    with open ('LLexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-anger-scores.csv', 'w', newline='') as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        writer.writerow(('Word', 'AngerIntensityScore'))\n",
    "        writer.writerows(lines)\n",
    "        \n",
    "anger_score = pd.read_csv('Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-anger-scores.csv')\n",
    "print(anger_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anticipation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-anticipation-scores.txt', 'r') as in_file:\n",
    "    stripped = (line.strip() for line in in_file)\n",
    "    lines = (line.split('\\t') for line in stripped if line)\n",
    "    with open (r'Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-anticipation-scores.csv', 'w', newline='') as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        writer.writerow(('Word', 'AnticipationIntensityScore'))\n",
    "        writer.writerows(lines)\n",
    "        \n",
    "anticipation_score = pd.read_csv(r'Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-anticipation-scores.csv')\n",
    "print(anticipation_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disgust score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-disgust-scores.txt', 'r') as in_file:\n",
    "    stripped = (line.strip() for line in in_file)\n",
    "    lines = (line.split('\\t') for line in stripped if line)\n",
    "    with open (r'Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-disgust-scores.csv', 'w', newline='') as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        writer.writerow(('Word', 'DisgustIntensityScore'))\n",
    "        writer.writerows(lines)\n",
    "        \n",
    "disgust_score = pd.read_csv(r'Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-disgust-scores.csv')\n",
    "print(disgust_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fear score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-fear-scores.txt', 'r') as in_file:\n",
    "    stripped = (line.strip() for line in in_file)\n",
    "    lines = (line.split('\\t') for line in stripped if line)\n",
    "    with open (r'Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-fear-scores.csv', 'w', newline='') as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        writer.writerow(('Word', 'FearIntensityScore'))\n",
    "        writer.writerows(lines)\n",
    "        \n",
    "fear_score = pd.read_csv(r'Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-fear-scores.csv')\n",
    "print(fear_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-joy-scores.txt', 'r') as in_file:\n",
    "    stripped = (line.strip() for line in in_file)\n",
    "    lines = (line.split('\\t') for line in stripped if line)\n",
    "    with open (r'Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-joy-scores.csv', 'w', newline='') as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        writer.writerow(('Word', 'JoyIntensityScore'))\n",
    "        writer.writerows(lines)\n",
    "        \n",
    "joy_score = pd.read_csv(r'Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-joy-scores.csv')\n",
    "print(joy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sadness score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-sadness-scores.txt', 'r') as in_file:\n",
    "    stripped = (line.strip() for line in in_file)\n",
    "    lines = (line.split('\\t') for line in stripped if line)\n",
    "    with open (r'Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-sadness-scores.csv', 'w', newline='') as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        writer.writerow(('Word', 'SadnessIntensityScore'))\n",
    "        writer.writerows(lines)\n",
    "        \n",
    "sadness_score = pd.read_csv(r'Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-sadness-scores.csv')\n",
    "print(sadness_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surprise score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-surprise-scores.txt', 'r') as in_file:\n",
    "    stripped = (line.strip() for line in in_file)\n",
    "    lines = (line.split('\\t') for line in stripped if line)\n",
    "    with open (r'Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-surprise-scores.csv', 'w', newline='') as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        writer.writerow(('Word', 'SurpriseIntensityScore'))\n",
    "        writer.writerows(lines)\n",
    "        \n",
    "surprise_score = pd.read_csv(r'Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-surprise-scores.csv')\n",
    "print(surprise_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trust score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-trust-scores.txt', 'r') as in_file:\n",
    "    stripped = (line.strip() for line in in_file)\n",
    "    lines = (line.split('\\t') for line in stripped if line)\n",
    "    with open (r'Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-trust-scores.csv', 'w', newline='') as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        writer.writerow(('Word', 'TrustIntensityScore'))\n",
    "        writer.writerows(lines)\n",
    "        \n",
    "trust_score = pd.read_csv(r'Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-trust-scores.csv')\n",
    "print(trust_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and convert NRC-Emotion-Lexicon-Wordlevel-v0.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'Lexicons/NRC_Emotion_Lexicon/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt', 'r') as in_file:\n",
    "    stripped = (line.strip() for line in in_file)\n",
    "    lines = (line.split('\\t') for line in stripped if line)\n",
    "    with open (r'Lexicons/NRC_Emotion_Lexicon/NRC-Emotion-Lexicon-Wordlevel-v0.92.csv', 'w', newline='') as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        writer.writerow(('Term', 'AffectCategory', 'AssociationImportFlag'))\n",
    "        writer.writerows(lines)\n",
    "\n",
    "emotion_lexicon_wordlevel = pd.read_csv(r'Lexicons/NRC_Emotion_Lexicon/NRC-Emotion-Lexicon-Wordlevel-v0.92.csv')\n",
    "print(emotion_lexicon_wordlevel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and convert NRC-VAD-Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'Lexicons/NRC_VAD_Lexicon/NRC-VAD-Lexicon.txt', 'r') as in_file:\n",
    "    stripped = (line.strip() for line in in_file)\n",
    "    lines = (line.split('\\t') for line in stripped if line)\n",
    "    with open (r'Lexicons/NRC_VAD_Lexicon/NRC-VAD-Lexicon.csv', 'w', newline='') as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        writer.writerow(('Word', 'Valence', 'Arrousal', 'Dominance'))\n",
    "        writer.writerows(lines)\n",
    "        \n",
    "vad_lexicon = pd.read_csv(r'Lexicons/NRC_VAD_Lexicon/NRC-VAD-Lexicon.csv')\n",
    "print(vad_lexicon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'Lexicons/NRC_VAD_Lexicon/NRC-VAD-Lexicon-v-scores.txt', 'r') as in_file:\n",
    "    stripped = (line.strip() for line in in_file)\n",
    "    lines = (line.split('\\t') for line in stripped if line)\n",
    "    with open (r'Lexicons/NRC_VAD_Lexicon/NRC-VAD-Lexicon-v-scores.csv', 'w', newline='') as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        writer.writerow(('Word', 'Valence'))\n",
    "        writer.writerows(lines)\n",
    "        \n",
    "vad_valence = pd.read_csv(r'Lexicons/NRC_VAD_Lexicon/NRC-VAD-Lexicon-v-scores.csv')\n",
    "print(vad_valence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arousal score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(r'Lexicons/NRC_VAD_Lexicon/NRC-VAD-Lexicon-a-scores.txt', 'r') as in_file:\n",
    "    stripped = (line.strip() for line in in_file)\n",
    "    lines = (line.split('\\t') for line in stripped if line)\n",
    "    with open (r'Lexicons/NRC_VAD_Lexicon/NRC-VAD-Lexicon-a-scores.csv', 'w', newline='') as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        writer.writerow(('Word', 'Arousal'))\n",
    "        writer.writerows(lines)\n",
    "        \n",
    "vad_arousal = pd.read_csv(r'Lexicons/NRC_VAD_Lexicon/NRC-VAD-Lexicon-a-scores.csv')\n",
    "print(vad_arousal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dominance score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(r'Lexicons/NRC_VAD_Lexicon/NRC-VAD-Lexicon-d-scores.txt', 'r') as in_file:\n",
    "    stripped = (line.strip() for line in in_file)\n",
    "    lines = (line.split('\\t') for line in stripped if line)\n",
    "    with open (r'Lexicons/NRC_VAD_Lexicon/NRC-VAD-Lexicon-d-scores.csv', 'w', newline='') as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        writer.writerow(('Word', 'Dominance'))\n",
    "        writer.writerows(lines)\n",
    "        \n",
    "vad_dominance = pd.read_csv(r'Lexicons/NRC_VAD_Lexicon/NRC-VAD-Lexicon-d-scores.csv')\n",
    "print(vad_dominance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_list = rmf.getSentencesMeanValues()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get emotion intensity values for each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anger_lex = pd.read_csv('Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-anger-scores.csv')\n",
    "anticipation_lex = pd.read_csv('Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-anticipation-scores.csv')\n",
    "disgust_lex = pd.read_csv('Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-disgust-scores.csv')\n",
    "fear_lex = pd.read_csv('Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-fear-scores.csv')\n",
    "joy_lex = pd.read_csv('Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-joy-scores.csv')\n",
    "sadness_lex = pd.read_csv('Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-sadness-scores.csv')\n",
    "surprise_lex = pd.read_csv('Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-surprise-scores.csv')\n",
    "trust_lex = pd.read_csv('Lexicons/NRC_Emotion_Intensity_Lexicon/NRC-Emotion-Intensity-trust-scores.csv')\n",
    "\n",
    "phrases_intensity_score = []\n",
    "for phrase in sentences_list:\n",
    "    phrase_score = {'anger' : 0, 'anticipation' : 0, 'disgust' : 0, 'fear' : 0, 'joy' : 0, 'sadness' : 0, 'surprise' : 0, 'trust' : 0}\n",
    "    for widx in range(len(phrase)):\n",
    "        word = phrase[widx]['Word'][0]\n",
    "        \n",
    "        anger_temp = anger_lex.loc[anger_lex['Word'] == word]\n",
    "        if not anger_temp.empty:\n",
    "            phrase_score['anger'] += anger_temp.iloc[:,1].values[0]\n",
    "        anticipation_temp = anticipation_lex.loc[anticipation_lex['Word'] == word]\n",
    "        if not anticipation_temp.empty:\n",
    "            phrase_score['anticipation'] += anticipation_temp.iloc[:,1].values[0]\n",
    "        disgust_temp = disgust_lex.loc[disgust_lex['Word'] == word]\n",
    "        if not disgust_temp.empty:\n",
    "            phrase_score['disgust'] += disgust_temp.iloc[:,1].values[0]\n",
    "        fear_temp = fear_lex.loc[fear_lex['Word'] == word]\n",
    "        if not fear_temp.empty:\n",
    "            phrase_score['fear'] += fear_temp.iloc[:,1].values[0] \n",
    "        joy_temp = joy_lex.loc[joy_lex['Word'] == word]\n",
    "        if not joy_temp.empty:\n",
    "            phrase_score['joy'] += joy_temp.iloc[:,1].values[0]\n",
    "        sadness_temp = sadness_lex.loc[sadness_lex['Word'] == word]\n",
    "        if not sadness_temp.empty:\n",
    "            phrase_score['sadness'] += sadness_temp.iloc[:,1].values[0]\n",
    "        surprise_temp = surprise_lex.loc[surprise_lex['Word'] == word]\n",
    "        if not surprise_temp.empty:\n",
    "            phrase_score['surprise'] += surprise_temp.iloc[:,1].values[0]\n",
    "        temp = trust_lex.loc[trust_lex['Word'] == word]\n",
    "        if not temp.empty:\n",
    "            phrase_score['trust'] += temp.iloc[:,1].values[0]       \n",
    "    phrases_intensity_score.append(phrase_score)\n",
    "    \n",
    "with open (r'Lexicons/Emotion_Intensity_Sentences.csv', 'w', newline='') as out_file:\n",
    "    csv_columns = ['anger', 'anticipation', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'trust']\n",
    "    writer = csv.DictWriter(out_file, fieldnames=csv_columns)\n",
    "    writer.writerow(('Anger', 'Anticipation', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise', 'Trust'))\n",
    "    for row in phrases_intensity_score:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create csv file for VAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCsvWithVAD(ar_list, va_list, do_list):\n",
    "    df = pd.DataFrame(columns=['IdSent', 'Arousal', 'Valence', 'Dominance'])\n",
    "   \n",
    "    for x in range(len(ar_list)):\n",
    "        ar = ar_list[x]\n",
    "        va = va_list[x]\n",
    "        do = do_list[x]\n",
    "        df.loc[len(df.index)] = [x, ar, va, do]\n",
    "\n",
    "    return df\n",
    "\n",
    "sentence_VAD = createCsvWithVAD(ar_list_x, va_list_y, do_list_z)\n",
    "sentence_VAD.to_csv('Lexicons/Sentence_VAD_Emotion_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create csv file for eye-tracker features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             MPS          TRT           GD          FFD          GPT  \\\n",
      "0    3393.726335  3272.114127  2271.848639  2042.908123  4918.966288   \n",
      "1    3541.701698  2037.391503  1254.270915  1211.811111  2808.687582   \n",
      "2    3393.698266  4614.541475  3705.400705  3282.506023  6345.915451   \n",
      "3            NaN          NaN          NaN          NaN          NaN   \n",
      "4    3361.964108  3248.623581  2384.391665  2072.423616  3890.354827   \n",
      "..           ...          ...          ...          ...          ...   \n",
      "385          NaN          NaN          NaN          NaN          NaN   \n",
      "386  3244.692796  2786.358364  2406.158397  2261.481086  4113.971587   \n",
      "387  3313.699684  1682.916126  1582.294697  1461.151840  1996.783153   \n",
      "388  3232.751306  1457.638845  1134.106443  1094.863225  1619.079096   \n",
      "389  3050.352390  3739.406460  3167.588070  2800.442616  4232.408994   \n",
      "\n",
      "          nFix  \n",
      "0    28.543305  \n",
      "1    14.513399  \n",
      "2    38.283378  \n",
      "3          NaN  \n",
      "4    28.731654  \n",
      "..         ...  \n",
      "385        NaN  \n",
      "386  24.201909  \n",
      "387  15.848052  \n",
      "388  13.030422  \n",
      "389  32.487379  \n",
      "\n",
      "[390 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "def createCsvWithValueForWords(mps_list, trt_list, gd_list, ffd_list, gpt_list, nfix_list):\n",
    "    df = pd.DataFrame(columns=['MPS', 'TRT', 'GD', 'FFD', 'GPT', 'nFix'])\n",
    "    for x in range(len(mps_list)):\n",
    "        mps = mps_list[x]\n",
    "        trt = trt_list[x]\n",
    "        gd = gd_list[x]\n",
    "        ffd = ffd_list[x]\n",
    "        gpt = gpt_list[x]\n",
    "        nfix = nfix_list[x]\n",
    "        df.loc[len(df.index)] = [mps, trt, gd, ffd, gpt, nfix]\n",
    "            \n",
    "    return df\n",
    "\n",
    "\n",
    "def findGazeValueForWords(sentences_list):\n",
    "    mps_list = []\n",
    "    trt_list = []\n",
    "    gd_list = []\n",
    "    ffd_list = []\n",
    "    gpt_list = []\n",
    "    nfix_list = []\n",
    "\n",
    "    for x in range(len(sentences_list)):\n",
    "        mps = []\n",
    "        trt = 0\n",
    "        gd = 0\n",
    "        ffd = 0\n",
    "        gpt = 0\n",
    "        nfix = 0\n",
    "        \n",
    "        for k in range(len(sentences_list[x])):\n",
    "            mps.append(sentences_list[x][k]['MPS'])\n",
    "            trt += sentences_list[x][k]['TRT']\n",
    "            gd += sentences_list[x][k]['GD']\n",
    "            ffd += sentences_list[x][k]['FFD']\n",
    "            gpt += sentences_list[x][k]['GPT']\n",
    "            nfix += sentences_list[x][k]['nFix']\n",
    "        mps_value = np.average(mps)\n",
    "        mps_list.append(mps_value) \n",
    "        trt_list.append(trt)\n",
    "        gd_list.append(gd)\n",
    "        ffd_list.append(ffd)\n",
    "        gpt_list.append(gpt)\n",
    "        nfix_list.append(nfix)\n",
    "        \n",
    "    return createCsvWithValueForWords(mps_list, trt_list, gd_list, ffd_list, gpt_list, nfix_list)\n",
    "\n",
    "sentence_ValuesOfWOrds = findGazeValueForWords(sentences_list)\n",
    "sentence_ValuesOfWOrds.to_csv('Lexicons/Sentence_Eye-Tracker_features_dataset.csv', index=False)\n",
    "print (sentence_ValuesOfWOrds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
